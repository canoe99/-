{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a110cf36",
   "metadata": {},
   "source": [
    "# å®‰è£…æ‰€éœ€çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ab8070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/canoe/anaconda3/lib/python3.11/site-packages (4.48.3)\n",
      "Requirement already satisfied: datasets in /Users/canoe/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: torch in /Users/canoe/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/canoe/anaconda3/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (2025.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six in /Users/canoe/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489b359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /Users/canoe/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89ad296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/canoe/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from accelerate) (0.5.2)\n",
      "Requirement already satisfied: filelock in /Users/canoe/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.2.0)\n",
      "Requirement already satisfied: requests in /Users/canoe/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c2ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.8.0\n",
      "Uninstalling keras-3.8.0:\n",
      "  Successfully uninstalled keras-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall keras -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7df7a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/8a/ed/e08afca471299b04a34cd548e64e89d0153eda0e6cf9b715356777e24774/tf_keras-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Obtaining dependency information for keras>=3.5.0 from https://files.pythonhosted.org/packages/fe/cf/aea9087c4d7fafe956a0cc0ff6c3327d10fb8442cda50f992a2186921fa0/keras-3.8.0-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/canoe/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /Users/canoe/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/canoe/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/canoe/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: keras, tf-keras\n",
      "Successfully installed keras-3.8.0 tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad20ba0",
   "metadata": {},
   "source": [
    "# æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5ce1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canoe/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00df2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½è®­ç»ƒæ•°æ®\n",
    "files = ['ç»æµtrain.csv', 'å†›äº‹train.csv', 'ç§‘æŠ€train.csv', 'ç¤¾ä¼štrain.csv', 'ä½“è‚²train.csv', 'æ–‡åŒ–train.csv', 'æ”¿æ²»train.csv']\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bde94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # è¯»å–æ¯ä¸ªæ–‡ä»¶\n",
    "    df = pd.read_csv(file)\n",
    "    # æ·»åŠ æ ‡ç­¾åˆ—\n",
    "    df['Label'] = file.split('train.csv')[0]  # æ–‡ä»¶åä½œä¸ºæ ‡ç­¾\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83bd41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå¹¶æ‰€æœ‰æ•°æ®\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd7a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€‰æ‹©å†…å®¹åˆ—å’Œæ ‡ç­¾åˆ—\n",
    "df = df[['Content', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b92805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ ‡ç­¾ç¼–ç \n",
    "le = LabelEncoder()\n",
    "df['Label'] = le.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576b700d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High-speed rail here and there in China (37/46)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High-speed rail here and there in China (36/46)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High-speed rail here and there in China (35/46)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High-speed rail here and there in China (34/46)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High-speed rail here and there in China (33/46)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Content  Label\n",
       "0  High-speed rail here and there in China (37/46)      6\n",
       "1  High-speed rail here and there in China (36/46)      6\n",
       "2  High-speed rail here and there in China (35/46)      6\n",
       "3  High-speed rail here and there in China (34/46)      6\n",
       "4  High-speed rail here and there in China (33/46)      6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹æ•°æ®\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66717831",
   "metadata": {},
   "source": [
    "# BERTæ¨¡å‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ed7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504bd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰Datasetç±»ï¼Œå°è£…æ•°æ®\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        # Tokenize the text and encode it\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18cf110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½BERTé¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a2fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['Content'].values, df['Label'].values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58cf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„Datasetå¯¹è±¡\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_len=128)\n",
    "val_dataset = TextDataset(X_val, y_val, tokenizer, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d75708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½BERTæ¨¡å‹ç”¨äºåºåˆ—åˆ†ç±»\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de91ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/canoe/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # è¾“å‡ºç»“æœç›®å½•\n",
    "    num_train_epochs=3,              # è®­ç»ƒè½®æ•°\n",
    "    per_device_train_batch_size=8,   # æ¯ä¸ªè®¾å¤‡ä¸Šçš„è®­ç»ƒæ‰¹æ¬¡å¤§å°\n",
    "    per_device_eval_batch_size=16,   # æ¯ä¸ªè®¾å¤‡ä¸Šçš„è¯„ä¼°æ‰¹æ¬¡å¤§å°\n",
    "    warmup_steps=500,                # å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,               # æƒé‡è¡°å‡\n",
    "    logging_dir='./logs',            # æ—¥å¿—ç›®å½•\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"      # æ¯ä¸ªepochè¿›è¡Œè¯„ä¼°\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c67bb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨Trainer APIè¿›è¡Œè®­ç»ƒ\n",
    "trainer = Trainer(\n",
    "    model=model,                         # è®­ç»ƒçš„BERTæ¨¡å‹\n",
    "    args=training_args,                  # è®­ç»ƒçš„å‚æ•°\n",
    "    train_dataset=train_dataset,         # è®­ç»ƒé›†\n",
    "    eval_dataset=val_dataset             # éªŒè¯é›†\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99854fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6749' max='26823' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6749/26823 2:07:40 < 6:19:51, 0.88 it/s, Epoch 0.75/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a97fe",
   "metadata": {},
   "source": [
    "# ä¿å­˜å¹¶åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66261fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert_model/tokenizer_config.json',\n",
       " './bert_model/special_tokens_map.json',\n",
       " './bert_model/vocab.txt',\n",
       " './bert_model/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "model.save_pretrained('./bert_model')\n",
    "tokenizer.save_pretrained('./bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c1da888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ¨¡å‹\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892e1ab",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e08f91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„æµ‹é›†æ•°æ®\n",
    "predict_text = open('predict.txt', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f837e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹é¢„æµ‹é›†è¿›è¡Œå¤„ç†\n",
    "predict_dataset = TextDataset(predict_text, [0]*len(predict_text), tokenizer, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e8567b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "model.eval()\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d11277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for item in predict_dataset:\n",
    "        input_ids = item['input_ids'].unsqueeze(0)  # å¢åŠ batchç»´åº¦\n",
    "        attention_mask = item['attention_mask'].unsqueeze(0)\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf59c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æ–‡åŒ–' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç§‘æŠ€' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ'\n",
      " 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ'\n",
      " 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ'\n",
      " 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ'\n",
      " 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ'\n",
      " 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'ç»æµ' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹'\n",
      " 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹'\n",
      " 'å†›äº‹' 'å†›äº‹' 'æ–‡åŒ–' 'å†›äº‹' 'æ”¿æ²»' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'æ–‡åŒ–' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹' 'å†›äº‹'\n",
      " 'ç§‘æŠ€' 'å†›äº‹' 'å†›äº‹' 'æ”¿æ²»' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€'\n",
      " 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€'\n",
      " 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€'\n",
      " 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç¤¾ä¼š' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€'\n",
      " 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€'\n",
      " 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç§‘æŠ€' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š'\n",
      " 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š'\n",
      " 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š'\n",
      " 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š'\n",
      " 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ç¤¾ä¼š' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²' 'ä½“è‚²'\n",
      " 'ä½“è‚²' 'ä½“è‚²' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–'\n",
      " 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–'\n",
      " 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–'\n",
      " 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–'\n",
      " 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–'\n",
      " 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ–‡åŒ–' 'æ”¿æ²»' 'æ”¿æ²»'\n",
      " 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»'\n",
      " 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»'\n",
      " 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»'\n",
      " 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»' 'æ”¿æ²»']\n"
     ]
    }
   ],
   "source": [
    "# å°†é¢„æµ‹ç»“æœè½¬æ¢å›åŸå§‹æ ‡ç­¾\n",
    "predicted_labels = le.inverse_transform(predictions)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d010a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
